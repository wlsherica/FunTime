Note：
前情提要 Hadoop job running in uber mode 

hadoop運行的邏輯 
hdfs是儲存部分
運算是mr 分散再集合（google發明的）

現在都是yarn mr2 （嚴格不正確）
yarn是基本架構只要是平行運算都可以處理
v2是跑在yarn上面，但不代表就是yarn

平行運算如何分配？
mr1 先從client這端跟hadoop機器溝通，例如hdfs的data node name node（檔案部分）
但是在運算部分，是job tracker task tracker以daemon方式執行

name node只是告訴你資料在哪裡
job會先找job tracker主控台，他會將任務分給不同機器上的task tracker
task tracker負責做運算
每一個daemon都跑在jvm上

mr1的缺點：由job tracker來安排，當他cluster很大的時候，scale out就不是線性效能產生
因為只有一台主控

mr2在yarn上有resource manager（rm）
rm會先找一台比較有空的～指定他為application manager（ap）
ap會再找幾台空弦的做node manager
ap做監控，rm做資源分配
每一個都跑在一個jvm上
如果工作量不大jvm一直開關資源不划算

uber mode就是改善這個情況jvm開開關關
小job就一個jvm從頭用到底，就不是平行運算
如何判斷小job？（這機制預設是關掉的，要人工on）
三項條件都成立才是小job
1. mapper < 10
2. reducer = 0, 1
3. data size < 1 block 

yarnsite.xml內可以做修改
有四個屬性需要調整才有用處
上述條件也可以改，但是數字只能改小，不能變大

應該是所有機器設定都要改
